<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Appendix</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<div id="header">
<h1 class="title">Appendix</h1>
</div>
<h1 id="appendix-b">APPENDIX B</h1>
<h1 id="introduction">Introduction</h1>
<p>In Appendix B, we use a more complicated simulation to illustrate the application of semi-parametric estimation methodologies. Similar to the main simulation in the chapter, and in Appendix A, we use a simple example with an exposure A, an outcome Y, and one confounding variable W. Following the example from the chapter, we can think of A as physical abuse, Y and psychopathology in adulthood, and W as childhood socioeconomic status.</p>
<h1 id="data-generating-model">Data Generating Model</h1>
<p>The simulation is based on the following model: <em>W</em> is uniform across integers 1-5, P(A = 1 | W) = 0.1200, 0.1025, 0.0850, 0.0675, 0.0500 for W = 1, 2, 3, 4, 5, respecitively. The model for <em>Y</em> is binomial, based on the logistic regression model:</p>
<p>{% raw %} <span class="math display">\[
\text{logit}(P(Y \mid A = a, W = w)) = b_{0} + b_{1}a + b_{2} \cdot (w − 1)
+ b_{3} \cdot (w − 1)^{2} + b_{4} \cdot a \cdot (w − 1)^{2}
\]</span> {% endraw %}</p>
<p>with {% raw %} ( b_{0}, b_{1}, b_{2}, b_{3}, b_{4} =  ( − 2, 1, −0.25, 0.05, −0.05 ) ) {% endraw %}.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### Data Generating Function
dat.gen<span class="fl">.2</span> =<span class="st"> </span>function(n, probsw, probsa, bY) {
    W =<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="dv">5</span>, n, <span class="dt">replace =</span> T, <span class="dt">prob =</span> probsw)
    A =<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, probsa[W])
    X =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, A, W -<span class="st"> </span><span class="dv">1</span>, (W -<span class="st"> </span><span class="dv">1</span>)^<span class="dv">2</span>, A *<span class="st"> </span>(W -<span class="st"> </span><span class="dv">1</span>)^<span class="dv">2</span>)
    PYgivenAW =<span class="st"> </span><span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span><span class="kw">exp</span>(-(X %*%<span class="st"> </span>bY)))
    Y =<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, PYgivenAW)
    <span class="kw">return</span>(<span class="kw">data.frame</span>(W, A, Y))
}

### Definies parameters of data-generating distribution probsw= P(W=w)
probsw =<span class="st"> </span><span class="kw">c</span>(<span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>, <span class="fl">0.2</span>)
#### parameters to define P(A=1 | W)
probsa =<span class="st"> </span><span class="kw">c</span>(<span class="kw">seq</span>(<span class="fl">0.2</span>, <span class="fl">0.05</span>, <span class="dt">length =</span> <span class="dv">5</span>))
#### parameters to define P(Y |A, W)
bY =<span class="st"> </span><span class="kw">c</span>(-<span class="dv">2</span>, <span class="fl">1.5</span>, -<span class="fl">0.25</span>, <span class="fl">0.1</span>, -<span class="fl">0.1</span>)
### Sample Size
n =<span class="st"> </span><span class="dv">1000</span>
### Random number seed so can replicate results
<span class="kw">set.seed</span>(<span class="dv">4041</span>)
### Use function with set paramters to generate random sample of data
dat =<span class="st"> </span><span class="kw">dat.gen.2</span>(n, probsw, probsa, bY)
### Get the true values of the relevant distributional parameters and plot the
### true distribuiton
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">par</span>(<span class="dt">mar =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">5</span>))
### w at the possible values
w =<span class="st"> </span><span class="dv">1</span>:<span class="dv">5</span>
### design matrix for model for Y given A=0, given W and P(Y|A=0,W)
Xt =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="dv">0</span>, w -<span class="st"> </span><span class="dv">1</span>, (w -<span class="st"> </span><span class="dv">1</span>)^<span class="dv">2</span>, <span class="dv">0</span>)
PYgivena0w =<span class="st"> </span><span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span><span class="kw">exp</span>(-(Xt %*%<span class="st"> </span>bY)))
### design matrix for model for Y given A=1, given W and P(Y|A=1,W)
Xt =<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, <span class="dv">1</span>, w -<span class="st"> </span><span class="dv">1</span>, (w -<span class="st"> </span><span class="dv">1</span>)^<span class="dv">2</span>, (w -<span class="st"> </span><span class="dv">1</span>)^<span class="dv">2</span>)
PYgivena1w =<span class="st"> </span><span class="dv">1</span>/(<span class="dv">1</span> +<span class="st"> </span><span class="kw">exp</span>(-(Xt %*%<span class="st"> </span>bY)))
### Plot True distribution of Y given A=a,W=w
<span class="kw">plot</span>(w, PYgivena1w, <span class="dt">pch =</span> <span class="st">&quot;1&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">xlab =</span> <span class="st">&quot;w&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;P(Y=1|A=a,W=w)&quot;</span>)
<span class="kw">points</span>(w, PYgivena0w, <span class="dt">pch =</span> <span class="st">&quot;0&quot;</span>)</code></pre></div>
<div class="figure">
<img src="AppendixBRoadmapChapter_files/figure-markdown_github/sim.dat-1.png" alt="stuff" />
<p class="caption">stuff</p>
</div>
<p><strong>Figure 1:</strong> True model of P(Y = 1 | A = a, W = w)</p>
<p>Figure 1 depicts the probabilities of the outcome <em>Y</em> for the exposed (the 1s) and the unexposed (the 0s), by categories of the <em>W</em>, or P(Y | A, W). The association of <em>A</em> with <em>Y</em> is stronger for lower values of <em>W</em>, as evidenced by the larger difference between the 1 and 0 data points on the plot. Using the example from the chapter, this depicts a situation in which physical abuse (<em>A</em>) has a stronger association with pychopathology in adulthood (<em>Y</em>) among those with lower childhood SES (<em>W</em>)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Make plot of P(A=1|W)
PAgivenW =<span class="st"> </span>probsa
<span class="kw">plot</span>(w, PAgivenW, <span class="dt">type =</span> <span class="st">&quot;s&quot;</span>, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="st">&quot;w&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Propensity Score: P(A=1|W=w)&quot;</span>,
    <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.2</span>))</code></pre></div>
<div class="figure">
<img src="AppendixBRoadmapChapter_files/figure-markdown_github/sim2.dat-1.png" alt="P(A = 1 | W)" />
<p class="caption">P(A = 1 | W)</p>
</div>
<p><strong>Figure 2:</strong> The true treatment mechanism</p>
<p>Figure 2 depicts the probabilities of the exposure <em>A</em> by categories of the <em>W</em>. The probability of of exposure A, also known as the propensity score, is higher for lower values of W. Using the example from the chapter, this depicts a situation in which there is a higher probability of physical abuse (A) among those with lower childhood SES (W).</p>
<p>After generating and examining the simulated data, we now calculate the true values of the parameters of interest from the simulated data.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">### organize the true distribution of Y given A=a,W=w into a a single data
### frame for use below
yprobdat =<span class="st"> </span><span class="kw">data.frame</span>(PYgivena0w, PYgivena1w)
yprobdat =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">W =</span> <span class="dv">1</span>:<span class="dv">5</span>, <span class="dt">pw =</span> probsw, yprobdat)
yprobdat =<span class="st"> </span><span class="kw">data.frame</span>(yprobdat, probsa)
## Get estimates of the parameters that makeup the the relevant parts of the
## distribution
<span class="kw">rm</span>(Y, A, W)
### est of P(Y|A=a,W=w)
<span class="kw">attach</span>(dat)
yprobobs =<span class="st"> </span><span class="ot">NULL</span>
for (i in <span class="dv">1</span>:<span class="dv">5</span>) {
    pyaw =<span class="st"> </span><span class="kw">mean</span>(Y[A ==<span class="st"> </span><span class="dv">1</span> &amp;<span class="st"> </span>W ==<span class="st"> </span>i])
    pyaw =<span class="st"> </span><span class="kw">c</span>(pyaw, <span class="kw">mean</span>(Y[A ==<span class="st"> </span><span class="dv">0</span> &amp;<span class="st"> </span>W ==<span class="st"> </span>i]))
    yprobobs =<span class="st"> </span><span class="kw">rbind</span>(yprobobs, pyaw)
}
<span class="kw">detach</span>(<span class="dv">2</span>)
### est of P(W=w)
<span class="kw">attach</span>(dat)
tt =<span class="st"> </span><span class="kw">table</span>(A, Y, W)
wtab =<span class="st"> </span>(<span class="kw">table</span>(W)/(<span class="kw">length</span>(W)))
<span class="kw">detach</span>(<span class="dv">2</span>)
### Organize est elements of distribution into one data frame
tabout =<span class="st"> </span><span class="ot">NULL</span>
for (i in <span class="dv">1</span>:<span class="dv">5</span>) {
    tabout =<span class="st"> </span><span class="kw">rbind</span>(tabout, <span class="kw">c</span>(wtab[i], tt[<span class="dv">2</span>, <span class="dv">2</span>, i], <span class="kw">sum</span>(tt[<span class="dv">2</span>, , i]), yprobobs[i,
        <span class="dv">1</span>], tt[<span class="dv">1</span>, <span class="dv">2</span>, i], <span class="kw">sum</span>(tt[<span class="dv">1</span>, , i]), yprobobs[i, <span class="dv">2</span>]))
}
<span class="kw">colnames</span>(tabout) =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;est.&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;pw&quot;</span>, <span class="st">&quot;ny1&quot;</span>, <span class="st">&quot;na1&quot;</span>, <span class="st">&quot;pya1w&quot;</span>, <span class="st">&quot;ny0&quot;</span>, <span class="st">&quot;na0&quot;</span>,
    <span class="st">&quot;pya0w&quot;</span>), <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)

res.out =<span class="st"> </span><span class="kw">cbind</span>(yprobdat[, <span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">3</span>)], <span class="dt">diff.tr =</span> yprobdat[, <span class="dv">4</span>] -<span class="st"> </span>yprobdat[,
    <span class="dv">3</span>], tabout, <span class="dt">diff.est =</span> tabout[, <span class="st">&quot;est.pya1w&quot;</span>] -<span class="st"> </span>tabout[, <span class="st">&quot;est.pya0w&quot;</span>])

### Estimates of CRD and other causal parameters using saturated
### (nonparametric) estimating model
crd.sat =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>(tabout[, <span class="dv">4</span>] -<span class="st"> </span>tabout[, <span class="dv">7</span>]))
#### est E(Y0)
ey0.sat =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>tabout[, <span class="dv">7</span>])
#### est E(Y1)
ey1.sat =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>tabout[, <span class="dv">4</span>])
### True CRD
crd.true =<span class="st"> </span><span class="kw">sum</span>(yprobdat[, <span class="dv">2</span>] *<span class="st"> </span>(yprobdat[, <span class="dv">4</span>] -<span class="st"> </span>yprobdat[, <span class="dv">3</span>]))
#### true E(Y0)
ey0.true =<span class="st"> </span><span class="kw">sum</span>(yprobdat[, <span class="dv">2</span>] *<span class="st"> </span>(yprobdat[, <span class="dv">3</span>]))
#### true E(Y1)
ey1.true =<span class="st"> </span><span class="kw">sum</span>(yprobdat[, <span class="dv">2</span>] *<span class="st"> </span>(yprobdat[, <span class="dv">4</span>]))
#### True EY
ey.true =<span class="st"> </span><span class="kw">sum</span>(yprobdat[, <span class="dv">2</span>] *<span class="st"> </span>yprobdat[, <span class="dv">4</span>] *<span class="st"> </span>yprobdat[, <span class="dv">5</span>] +<span class="st"> </span>(yprobdat[, <span class="dv">2</span>] *
<span class="st">    </span>yprobdat[, <span class="dv">3</span>] *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span>yprobdat[, <span class="dv">5</span>])))
### true CPAR
cpar.true =<span class="st"> </span>ey.true -<span class="st"> </span>ey0.true
### est CPAR from saturated model
cpar.sat =<span class="st"> </span><span class="kw">mean</span>(dat[, <span class="st">&quot;Y&quot;</span>]) -<span class="st"> </span>ey0.sat
## Figure for observed data
w =<span class="st"> </span><span class="dv">1</span>:<span class="dv">5</span>
a =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="co"># par(mar = c(5,5,2,5))</span>
<span class="kw">plot</span>(w, yprobobs[, <span class="dv">1</span>], <span class="dt">pch =</span> <span class="st">&quot;1&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.4</span>), <span class="dt">xlab =</span> <span class="st">&quot;w&quot;</span>, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">hat</span>(P),
    <span class="st">&quot;(Y=1|A=a,W=w)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)))
<span class="kw">points</span>(w, yprobobs[, <span class="dv">2</span>], <span class="dt">pch =</span> <span class="st">&quot;0&quot;</span>)</code></pre></div>
<div class="figure">
<img src="AppendixBRoadmapChapter_files/figure-markdown_github/get.true-1.png" alt="Figure 3: {% raw %} ( (Y = 1 A = a, W = w) ) {% endraw %} based on saturated model" />
<p class="caption">Figure 3: {% raw %} ( (Y = 1 A = a, W = w) ) {% endraw %} based on saturated model</p>
</div>
<p><strong>Figure 3:</strong> Estimated P(Y = 1 | A = a, W = w) based on saturated model.</p>
<p>This results in the following true value of the causal risk difference (CRD):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Accumulate results so far into a data.frame and table
dt.out =<span class="st"> </span><span class="kw">data.frame</span>(ey0.true, ey1.true, ey.true, crd.true, cpar.true)</code></pre></div>
<p>We examine the results in Table 1.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(knitr)
knitr::<span class="kw">kable</span>(dt.out, <span class="dt">format =</span> <span class="st">&quot;markdown&quot;</span>)</code></pre></div>
<p><strong>Table 1:</strong> True Parameter Values.</p>
<table>
<thead>
<tr class="header">
<th align="right">ey0.true</th>
<th align="right">ey1.true</th>
<th align="right">ey.true</th>
<th align="right">crd.true</th>
<th align="right">cpar.true</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.133264</td>
<td align="right">0.2744858</td>
<td align="right">0.1559951</td>
<td align="right">0.1412218</td>
<td align="right">0.0227311</td>
</tr>
</tbody>
</table>
<h1 id="estimators">Estimators</h1>
<p>In next subsections, we explore estimation using different methods with different assumptions from nonparametric model (no assumptions) to assuming smoother (more parametric) models.</p>
<h1 id="nonparametric-model">Nonparametric Model</h1>
<p>For this, we simply get the proportion of Y = 1 among the 10 unique groups defined by both <em>A</em> and <em>W</em>. The substitution estimator in general is:</p>
<p>{% raw %} <span class="math display">\[
\hat{crd} = \frac{1}{n} \sum_{i=1}^{n} \hat{Y}(1, W_{i}) - \hat{Y}(0,W_{i})
\]</span> {% endraw %}</p>
<p>where {% raw %} ( (a,W) ) {% endraw %} is simply the predicted value (whatever the procedure used) of <em>Y</em> when <em>A</em> is set to <em>a</em> for a subject, but one uses their observed <em>W</em>. To esitmate the populaiton attributable risk (or E(Y(0)−Y),the resulting estimator is very similar:</p>
<p>{% raw %} <span class="math display">\[
\widehat{cpar} = \frac{1}{n} \sum_{i = 1}^{n} \hat{Y}(A_i, W_i) -
\hat{Y}(0, W_i)
\]</span> {% endraw %}</p>
<p>where {% raw %} ( (A_i, W_i) ) {% endraw %} is the predicted value for both the observed value of the confounders, {% raw %} ( W_{i} ) {% endraw %} and the observed treatment {% raw %}( A_{i} ) {% endraw %}.</p>
<p>When we use the nonparametric (or &quot;saturated&quot;) model here, it's the equivalent of fitting a logistic regression model of form</p>
<p>{% raw %} <span class="math display">\[
\text{logit}(P(Y \mid A = a, W = w)) = b_{0} + b_{1} a + \sum_{j = 2}^{5}
b_{j} \cdot I(w = j) + c_{j} \cdot a \cdot I(w = j)
\]</span> {% endraw %}</p>
<p>which simply has all the appropriate dummy variables for the categories the interactions of those with the variable of interest. Given this model assumes nothing about the relationship of <em>Y</em> to (<em>A</em>, <em>W</em>), we know our resulting estimate will have no bias, but might be unnecessarily variable. When we fit such a model, we get the following results. See also Figure <strong>?</strong>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">#################### Estimated EY(0)
<span class="kw">print</span>(ey0.sat)</code></pre></div>
<pre><code>## [1] 0.1305999</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## EY(1)
<span class="kw">print</span>(ey1.sat)</code></pre></div>
<pre><code>## [1] 0.2508041</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## EY
<span class="kw">print</span>(<span class="kw">mean</span>(dat[, <span class="st">&quot;Y&quot;</span>]))</code></pre></div>
<pre><code>## [1] 0.145</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## crd
<span class="kw">print</span>(crd.sat)</code></pre></div>
<pre><code>## [1] 0.1202042</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## crd
<span class="kw">print</span>(cpar.sat)</code></pre></div>
<pre><code>## [1] 0.01440006</code></pre>
<h1 id="simpler-logistic-regression-model">Simpler Logistic Regression Model</h1>
<p>The most common way that researchers estimate the effect of <em>A</em> on <em>Y</em>, is to assume a parametric model, adjusting for <em>W</em>. Here we fit a main terms logistic regression, as was done in the analysis in the chapter. Specifically, we fit a simpler model similar to above but without the interaction terms:</p>
<p>{% raw %} <span class="math display">\[
\text{logit}(P(Y \mid A = a, W = w)) = b_{0} + b_{1} a + \sum_{j = 2}^{5}
b_{j} \cdot I(w = j)
\]</span> {% endraw %}</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Fit linear-logistic model (not saturated) for Y|A,W
glm1 =<span class="st"> </span><span class="kw">glm</span>(Y ~<span class="st"> </span>A +<span class="st"> </span><span class="kw">factor</span>(W), <span class="dt">data =</span> dat, <span class="dt">family =</span> <span class="kw">binomial</span>())
## Function to convert results of glm into interpretable parameters, such as
## odds ratios and provide inference
lreg.or &lt;-<span class="st"> </span>function(glm.mod, <span class="dt">robust =</span> <span class="ot">FALSE</span>, <span class="dt">mult =</span> <span class="ot">NULL</span>) {
    <span class="co"># robust indicates sandwich estimator mult is the OR for the &#39;mult&#39; change</span>
    <span class="co"># in the corresponding predictors</span>
    if (robust ==<span class="st"> </span><span class="ot">TRUE</span>) {
        glm<span class="fl">.1</span> &lt;-<span class="st"> </span><span class="kw">robcov</span>(glm.mod)
        se =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">diag</span>(glm<span class="fl">.1</span>$var))
        cf =<span class="st"> </span>glm<span class="fl">.1</span>$coefficients
        lreg.coeffs =<span class="st"> </span><span class="kw">cbind</span>(cf, se)
    }
    if (robust ==<span class="st"> </span><span class="ot">FALSE</span>) {
        lreg.coeffs &lt;-<span class="st"> </span><span class="kw">coef</span>(<span class="kw">summary</span>(glm.mod))
    }
    p =<span class="st"> </span><span class="kw">dim</span>(lreg.coeffs)[<span class="dv">1</span>]
    if (<span class="kw">is.null</span>(mult)) {
        mult =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">1</span>, p -<span class="st"> </span><span class="dv">1</span>)
    }
    l95ci &lt;-<span class="st"> </span><span class="kw">exp</span>(mult *<span class="st"> </span>(lreg.coeffs[<span class="dv">2</span>:p, <span class="dv">1</span>] -<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>lreg.coeffs[<span class="dv">2</span>:p, <span class="dv">2</span>]))
    or &lt;-<span class="st"> </span><span class="kw">exp</span>(mult *<span class="st"> </span>lreg.coeffs[<span class="dv">2</span>:p, <span class="dv">1</span>])
    u95ci &lt;-<span class="st"> </span><span class="kw">exp</span>(mult *<span class="st"> </span>(lreg.coeffs[<span class="dv">2</span>:p, <span class="dv">1</span>] +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>lreg.coeffs[<span class="dv">2</span>:p, <span class="dv">2</span>]))
    pvalue =<span class="st"> </span>(<span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(lreg.coeffs[, <span class="dv">1</span>]/lreg.coeffs[, <span class="dv">2</span>]))))[<span class="dv">2</span>:p]

    lreg.or &lt;-<span class="st"> </span><span class="kw">cbind</span>(l95ci, or, u95ci, pvalue)
    lreg.or
}</code></pre></div>
<p>When we fit this, we get the following logistic regression results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Show results of glm fit
<span class="kw">summary</span>(glm1)</code></pre></div>
<pre><code>##
## Call:
## glm(formula = Y ~ A + factor(W), family = binomial(), data = dat)
##
## Deviance Residuals:
##     Min       1Q   Median       3Q      Max
## -0.9567  -0.5535  -0.5107  -0.4418   2.1795
##
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept)  -1.9713     0.2148  -9.176  &lt; 2e-16 ***
## A             0.8861     0.2450   3.617 0.000298 ***
## factor(W)2   -0.2673     0.3001  -0.891 0.373180
## factor(W)3   -0.3063     0.3247  -0.943 0.345542
## factor(W)4    0.1726     0.2839   0.608 0.543111
## factor(W)5    0.5410     0.2711   1.996 0.045972 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
##     Null deviance: 827.87  on 999  degrees of freedom
## Residual deviance: 805.95  on 994  degrees of freedom
## AIC: 817.95
##
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lreg.or</span>(glm1)</code></pre></div>
<pre><code>##                l95ci        or    u95ci       pvalue
## A          1.5007134 2.4256369 3.920612 0.0002979676
## factor(W)2 0.4250482 0.7654569 1.378489 0.3731804955
## factor(W)3 0.3895747 0.7361784 1.391155 0.3455417969
## factor(W)4 0.6812995 1.1884178 2.073004 0.5431111274
## factor(W)5 1.0097122 1.7177753 2.922369 0.0459718303</code></pre>
<p>We can also look at a plot of the model (see figure ).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Plot the estimated parts of distribution from both simpler logistic model
## and saturated model.
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
<span class="kw">plot</span>(w, yprobobs[, <span class="dv">1</span>], <span class="dt">pch =</span> <span class="st">&quot;1&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">xlab =</span> <span class="st">&quot;w&quot;</span>, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">hat</span>(P),
    <span class="st">&quot;(Y=1|A=a,W=w)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)))
<span class="kw">points</span>(w, yprobobs[, <span class="dv">2</span>], <span class="dt">pch =</span> <span class="st">&quot;0&quot;</span>)
datn =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">W =</span> <span class="dv">1</span>:<span class="dv">5</span>, <span class="dt">A =</span> <span class="dv">0</span>)
predA0 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">lines</span>(w, predA0, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)
datn =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">W =</span> <span class="dv">1</span>:<span class="dv">5</span>, <span class="dt">A =</span> <span class="dv">1</span>)
predA1 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
<span class="kw">lines</span>(w, predA1, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="AppendixBRoadmapChapter_files/figure-markdown_github/plot.glm-1.png" alt="((Y=1 A=a,W=w)) based on simpler model - the lines are the fit from simpler model whereas points from saturated model" />
<p class="caption">((Y=1 A=a,W=w)) based on simpler model - the lines are the fit from simpler model whereas points from saturated model</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Update results data.frame with glm results
res.out =<span class="st"> </span><span class="kw">cbind</span>(res.out, <span class="dt">glm.predA1 =</span> predA1, <span class="dt">glm.predA0 =</span> predA0, <span class="dt">glm.diff =</span> predA1 -
<span class="st">    </span>predA0)</code></pre></div>
<p>Now, using this model result to derive {% raw %} ( (a, W) ) {% endraw %} for our crd estimator, we get:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Use model to predict Y at A=0,W and A=1,W.
datn =<span class="st"> </span>dat
predA =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
### Est E(Y)
eyA.glm =<span class="st"> </span><span class="kw">mean</span>(predA)
### Est E(Y0)
datn[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">0</span>
predA0 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
eyA0.glm =<span class="st"> </span><span class="kw">mean</span>(predA0)
### Est E(Y1)
datn[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">1</span>
predA1 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
eyA1.glm =<span class="st"> </span><span class="kw">mean</span>(predA1)
### Est CRD
crd.glm =<span class="st"> </span>eyA1.glm -<span class="st"> </span>eyA0.glm
### Est CPAR
cpar.glm =<span class="st"> </span>eyA.glm -<span class="st"> </span>eyA0.glm
<span class="co"># EY(0)</span>
<span class="kw">print</span>(eyA0.glm)</code></pre></div>
<pre><code>## [1] 0.1306585</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># EY(1)</span>
<span class="kw">print</span>(eyA1.glm)</code></pre></div>
<pre><code>## [1] 0.2644214</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># EY</span>
<span class="kw">print</span>(eyA.glm)</code></pre></div>
<pre><code>## [1] 0.145</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># crd</span>
<span class="kw">print</span>(crd.glm)</code></pre></div>
<pre><code>## [1] 0.1337629</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># cpar</span>
<span class="kw">print</span>(cpar.glm)</code></pre></div>
<pre><code>## [1] 0.01434152</code></pre>
<h1 id="semiparametric-machine-learning-superlearner">Semiparametric Machine Learning (SuperLearner)</h1>
<p>To demonstrate an alternative approach which is based upon flexible, data adaptive methods, we also fit the the regression model using the so-called SuperLearner. SuperLearner allows the user to enter a library of potential model selection routines, such as stepwise procedures, polynomial splines, and classification and regression-trees , and uses cross-validation to select the best routine or weighted combination of routines without overfitting. Our implementation is based on using 2 simple learners: simple logistic regression with only main terms for both <em>A</em> and unordered categorical <em>W</em>. We also implement stepwise logistic regression, allowing for main terms and 2-way interactions (e.g., {% raw %} ( I(W = w) A) ) {% endraw %}. See Figure for results.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Examples of wrappers of learners to add to SL
SL.inter2 =<span class="st"> </span>function(Y, X, newX, family, <span class="dt">direction =</span> <span class="st">&quot;both&quot;</span>, <span class="dt">trace =</span> <span class="dv">0</span>, <span class="dt">k =</span> <span class="dv">2</span>,
    ...) {
    fit.glm &lt;-<span class="st"> </span><span class="kw">glm</span>(Y ~<span class="st"> </span>., <span class="dt">data =</span> X, <span class="dt">family =</span> family)
    fit.step &lt;-<span class="st"> </span><span class="kw">step</span>(fit.glm, <span class="dt">scope =</span> <span class="kw">list</span>(<span class="dt">lower =</span> Y ~<span class="st"> </span>A, <span class="dt">upper =</span> Y ~<span class="st"> </span>.^<span class="dv">2</span>),
        <span class="dt">direction =</span> direction, <span class="dt">trace =</span> trace, <span class="dt">k =</span> k)
    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit.step, <span class="dt">newdata =</span> newX, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
    fit &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">object =</span> fit.step)
    out &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">pred =</span> pred, <span class="dt">fit =</span> fit)
    <span class="kw">class</span>(out$fit) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.step&quot;</span>)
    <span class="kw">return</span>(out)
}
## Library of learners for SL
SL.library =<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;SL.glm&quot;</span>, <span class="st">&quot;SL.inter2&quot;</span>)
## Make basis functions for use in SL
<span class="kw">attach</span>(dat)
newdat =<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="kw">factor</span>(W -<span class="st"> </span><span class="dv">1</span>))
<span class="kw">detach</span>(<span class="dv">2</span>)
newdat =<span class="st"> </span><span class="kw">data.frame</span>(dat, newdat)
newdat =<span class="st"> </span>newdat[, -<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)]
<span class="kw">names</span>(newdat)[<span class="dv">3</span>:<span class="dv">6</span>] =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;W&quot;</span>, <span class="dv">2</span>:<span class="dv">5</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
newX =<span class="st"> </span>newdat[, -<span class="dv">2</span>]
YY =<span class="st"> </span>newdat[, <span class="dv">2</span>]
## Fit SL
SLfit =<span class="st"> </span><span class="kw">SuperLearner</span>(<span class="dt">Y =</span> YY, <span class="dt">X =</span> newX, <span class="dt">family =</span> <span class="kw">binomial</span>(), <span class="dt">SL.library =</span> SL.library)
## Get prediction of Y at A=0,W
newX2 =<span class="st"> </span>newX
newX2[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">0</span>
p0 =<span class="st"> </span><span class="kw">predict</span>(SLfit, newX2)$pred
## Get prediction of Y at A=1,W
newX2[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">1</span>
p1 =<span class="st"> </span><span class="kw">predict</span>(SLfit, newX2)$pred
## Update results data frame
res.out =<span class="st"> </span><span class="kw">cbind</span>(res.out, <span class="dt">SL.predA =</span> p1, <span class="dt">SL.predA0 =</span> p0, <span class="dt">SL.diff =</span> p1 -<span class="st"> </span>p0)
## Est E(Y1),E(Y0), CRD, EY, CPAR, respectively
ey1.SL =<span class="st"> </span><span class="kw">mean</span>(p1)
ey0.SL =<span class="st"> </span><span class="kw">mean</span>(p0)
crd.SL =<span class="st"> </span><span class="kw">mean</span>(p1 -<span class="st"> </span>p0)
ey.SL =<span class="st"> </span><span class="kw">mean</span>(SLfit$SL.predict[<span class="dv">1</span>:<span class="dv">10</span>])
cpar.SL =<span class="st"> </span>ey.SL -<span class="st"> </span><span class="kw">mean</span>(p0)
## Plot the SL fit to data
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
w =<span class="st"> </span><span class="dv">1</span>:<span class="dv">5</span>
<span class="kw">plot</span>(w, yprobobs[, <span class="dv">1</span>], <span class="dt">pch =</span> <span class="st">&quot;1&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>), <span class="dt">xlab =</span> <span class="st">&quot;w&quot;</span>, <span class="dt">ylab =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="kw">hat</span>(P),
    <span class="st">&quot;(Y=1|A=a,W=w)&quot;</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)))
<span class="kw">points</span>(w, yprobobs[, <span class="dv">2</span>], <span class="dt">pch =</span> <span class="st">&quot;0&quot;</span>)
plotdat =<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="kw">factor</span>(w -<span class="st"> </span><span class="dv">1</span>))
plotdat =<span class="st"> </span>plotdat[, -<span class="dv">1</span>]
plotdat =<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">A =</span> <span class="dv">0</span>, plotdat)
<span class="kw">names</span>(plotdat)[<span class="dv">2</span>:<span class="dv">5</span>] =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;W&quot;</span>, <span class="dv">2</span>:<span class="dv">5</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
p0 =<span class="st"> </span><span class="kw">predict</span>(SLfit, plotdat)$pred
<span class="kw">lines</span>(w, p0, <span class="dt">lty =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="dv">1</span>)
plotdat[, <span class="dv">1</span>] =<span class="st"> </span><span class="dv">1</span>
p1 =<span class="st"> </span><span class="kw">predict</span>(SLfit, plotdat)$pred
<span class="kw">lines</span>(w, p1, <span class="dt">lty =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="dv">2</span>)</code></pre></div>
<div class="figure">
<img src="AppendixBRoadmapChapter_files/figure-markdown_github/SL1-1.png" alt="{% raw %} ( (Y=1 A=a, W=w) ) {% endraw %} based on SL fit - the lines are the fit from SL fit whereas points from saturated model" />
<p class="caption">{% raw %} ( (Y=1 A=a, W=w) ) {% endraw %} based on SL fit - the lines are the fit from SL fit whereas points from saturated model</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Udate results
res.out =<span class="st"> </span><span class="kw">cbind</span>(res.out, <span class="dt">SL.predA1 =</span> p1, <span class="dt">SL.predA0 =</span> p0, <span class="dt">SL.diff =</span> p1 -<span class="st"> </span>p0)</code></pre></div>
<h1 id="tmle">TMLE</h1>
<p>Using SuperLearner to fit the outcome model has the potential to do better than the simple parametric model. However, the model fit will not be optimal for the parameter of interest, and there is no theory based way to get statistical inference (confidence intervals). Targeted Maximum Likelihood Estimation (TMLE) works by modifying the initial estimator based on data-adaptive fitting of the outcome model, such that the resulting model provides a more targeted bias-variance trade-off for the parameter of interest. TMLE uses a simple augmentation of the original fit of E(Y | A, W), by adding a &quot;clever covariate&quot; that is related to the propensity score, also known as the treatment mechanism P(A = 1 | W). Informally, one can think of this covariate as capturing residual confounding specific to the parameter of interest. Finally, we used TMLE, using the SL fit discussed above as the initial fit, and using simple logistic regression to derive the propensity score used in the clever covariate.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## wrapper for simple (mispecified) glm learner
SL.glm.simp =<span class="st"> </span>function(Y, X, newX, family, obsWeights, ...) {
    fit.glm &lt;-<span class="st"> </span><span class="kw">glm</span>(Y ~<span class="st"> </span>W, <span class="dt">data =</span> X, <span class="dt">family =</span> family, <span class="dt">weights =</span> obsWeights)
    pred &lt;-<span class="st"> </span><span class="kw">predict</span>(fit.glm, <span class="dt">newdata =</span> newX, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
    fit &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">object =</span> fit.glm)
    <span class="kw">class</span>(fit) &lt;-<span class="st"> &quot;SL.glm&quot;</span>
    out &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">pred =</span> pred, <span class="dt">fit =</span> fit)
    <span class="kw">return</span>(out)
}
## specifiy library for estimate P(A=1|W)
gl.lib =<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;SL.glm.simp&quot;</span>)
## Make data structure expected for input into TMLE
YY =<span class="st"> </span>dat[, <span class="st">&quot;Y&quot;</span>]
AA =<span class="st"> </span>newX[, <span class="dv">1</span>]
WW =<span class="st"> </span><span class="kw">data.frame</span>(newX[, <span class="dv">2</span>:<span class="dv">5</span>], <span class="dt">W =</span> dat[, <span class="st">&quot;W&quot;</span>])
## Run TMLE
tmle.rest =<span class="st"> </span><span class="kw">tmle</span>(YY, AA, WW, <span class="dt">Q.SL.library =</span> <span class="st">&quot;SL.inter2&quot;</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
    <span class="dt">verbose =</span> <span class="ot">TRUE</span>, <span class="dt">gform =</span> A ~<span class="st"> </span>W)</code></pre></div>
<pre><code>##  Estimating initial regression of Y on A and W
##   using SuperLearner
##  Estimating treatment mechanism
##  Estimating missingness mechanism</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Est CRD
crd.TMLE =<span class="st"> </span>tmle.rest$estimates$crd$psi
## Est CPAR
cpar.tmle =<span class="st"> </span>ey.SL -<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">1</span>])
W =<span class="st"> </span>WW[, <span class="dv">5</span>]
## Get tmle estimate of ptmleQ1=E(Y|A=1,W) and ptmleQ0=E(Y|A=0,W)
ptmleQ1 =<span class="st"> </span><span class="ot">NULL</span>
ptmleQ0 =<span class="st"> </span><span class="ot">NULL</span>
for (i in <span class="dv">1</span>:<span class="dv">5</span>) {
    ptmleQ1 =<span class="st"> </span><span class="kw">c</span>(ptmleQ1, <span class="kw">mean</span>(tmle.rest$Qstar[W ==<span class="st"> </span>i, <span class="dv">2</span>]))
    ptmleQ0 =<span class="st"> </span><span class="kw">c</span>(ptmleQ0, <span class="kw">mean</span>(tmle.rest$Qstar[W ==<span class="st"> </span>i, <span class="dv">1</span>]))
}
## est EY1
ey1.tmle =<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">2</span>])
## est EY0
ey0.tmle =<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">1</span>])
## Update results data frame
res.out =<span class="st"> </span><span class="kw">cbind</span>(res.out, <span class="dt">tmle.predA1 =</span> ptmleQ1, <span class="dt">tmle.predA0 =</span> ptmleQ0, <span class="dt">tmle.diff =</span> ptmleQ1 -
<span class="st">    </span>ptmleQ0)

xx =<span class="st"> </span><span class="kw">c</span>(<span class="ot">NA</span>, <span class="ot">NA</span>, ey1.true, ey0.true, crd.true, <span class="ot">NA</span>, <span class="ot">NA</span>, <span class="ot">NA</span>, ey1.sat, <span class="ot">NA</span>, <span class="ot">NA</span>, ey0.sat,
    crd.sat, eyA1.glm, eyA0.glm, crd.glm, ey1.SL, ey0.SL, crd.SL, ey1.tmle,
    ey0.tmle, crd.TMLE)
res.out2 =<span class="st"> </span><span class="kw">rbind</span>(res.out, xx)
res.out2 =<span class="st"> </span><span class="kw">data.frame</span>(res.out2)
res.out2[, <span class="dv">1</span>] =<span class="st"> </span><span class="kw">as.character</span>(res.out2[, <span class="dv">1</span>])
res.out2[<span class="dv">6</span>, <span class="dv">1</span>] =<span class="st"> &quot;Marginals&quot;</span></code></pre></div>
<h1 id="inference-confidence-intervals-p-values">Inference (confidence intervals, p-values)</h1>
<p>For all estimators, one can derive the asymptotic inference using the nonparametric bootstrap. The basic algorithm is 1) generate the estimate using the data set as we've described, 2) randomly re-sample the units (more on this in a sec) with replacement, to generat a new data set of the same &quot;size&quot; as the original, 3) re-do the estimator to generate a new estimate on this simulated data set, 4) repeate 2-3 say 1000 times, each time storying the estimate. In the end, one derives say 1000 estimates on different re-sampled data sets, and the SE calculated simple as the sample standard deviation of these 1000 estimates. The intution of this procedure is that we are mimicking the sampling variability that would result from a new equivalent experiment to the one orignally done. That's where the definition of a unit comes in. If we have independently sampled individuals, then our bootstrap should mimic that by randomly re-sampling the rows of the data set. However, if our design was, for instance, a random draw of clusters of individuals, say by neighborhoods, then our bootstrap would randomly re-sample the clusters of individuals represented by these neighborhoods. In any case, the idea is to mimic the design when running the bootstrap.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Initialize objects to fill up during bootstrap iterations
glm.orig =<span class="st"> </span>glm1
dat.orig =<span class="st"> </span>dat
boot.sat =<span class="st"> </span><span class="ot">NULL</span>
boot.glm =<span class="st"> </span><span class="ot">NULL</span>
boot.SL =<span class="st"> </span><span class="ot">NULL</span>
boot.tmle =<span class="st"> </span><span class="ot">NULL</span>
## Need this rownumber variable below
ind =<span class="st"> </span><span class="dv">1</span>:n
## Number of bootstrap iterations = B
B =<span class="st"> </span><span class="dv">1000</span>
## Start bootstrap loop
for (b in <span class="dv">1</span>:B) {
    ## Randomly re-sample observations with replacement a total size n
    dat =<span class="st"> </span>dat.orig[<span class="kw">sample</span>(ind, n, <span class="dt">replace =</span> T), ]
    ## Repeates the estimation procedures discussed above and updates the
    ## corresponding data.frames storing the information after each iteration,
    ## b=1,...,B.

    <span class="kw">attach</span>(dat)
    yprobobs =<span class="st"> </span><span class="ot">NULL</span>
    for (i in <span class="dv">1</span>:<span class="dv">5</span>) {
        pyaw =<span class="st"> </span><span class="kw">mean</span>(Y[A ==<span class="st"> </span><span class="dv">1</span> &amp;<span class="st"> </span>W ==<span class="st"> </span>i])
        pyaw =<span class="st"> </span><span class="kw">c</span>(pyaw, <span class="kw">mean</span>(Y[A ==<span class="st"> </span><span class="dv">0</span> &amp;<span class="st"> </span>W ==<span class="st"> </span>i]))
        yprobobs =<span class="st"> </span><span class="kw">rbind</span>(yprobobs, pyaw)
    }
    <span class="kw">detach</span>(<span class="dv">2</span>)
    <span class="kw">attach</span>(dat)
    tt =<span class="st"> </span><span class="kw">table</span>(A, Y, W)
    wtab =<span class="st"> </span>(<span class="kw">table</span>(W)/(<span class="kw">length</span>(W)))
    <span class="kw">detach</span>(<span class="dv">2</span>)
    tabout =<span class="st"> </span><span class="ot">NULL</span>
    for (i in <span class="dv">1</span>:<span class="dv">5</span>) {
        tabout =<span class="st"> </span><span class="kw">rbind</span>(tabout, <span class="kw">c</span>(wtab[i], tt[<span class="dv">2</span>, <span class="dv">2</span>, i], <span class="kw">sum</span>(tt[<span class="dv">2</span>, , i]), yprobobs[i,
            <span class="dv">1</span>], tt[<span class="dv">1</span>, <span class="dv">2</span>, i], <span class="kw">sum</span>(tt[<span class="dv">1</span>, , i]), yprobobs[i, <span class="dv">2</span>]))
    }
    crd.sat.b =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>(tabout[, <span class="dv">4</span>] -<span class="st"> </span>tabout[, <span class="dv">7</span>]))
    ey1.sat.b =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>tabout[, <span class="dv">4</span>])
    ey0.sat.b =<span class="st"> </span><span class="kw">sum</span>(tabout[, <span class="dv">1</span>] *<span class="st"> </span>tabout[, <span class="dv">7</span>])
    cpar.sat.b =<span class="st"> </span><span class="kw">mean</span>(dat[, <span class="st">&quot;Y&quot;</span>]) -<span class="st"> </span>ey0.sat
    ey.sat.b =<span class="st"> </span><span class="kw">mean</span>(dat[, <span class="st">&quot;Y&quot;</span>])
    boot.sat =<span class="st"> </span><span class="kw">rbind</span>(boot.sat, <span class="kw">c</span>(ey0.sat.b, ey1.sat.b, ey.sat.b, crd.sat.b,
        cpar.sat.b))
    ## Figure for observed data
    w =<span class="st"> </span><span class="dv">1</span>:<span class="dv">5</span>
    a =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
    glm1 =<span class="st"> </span><span class="kw">glm</span>(Y ~<span class="st"> </span>A +<span class="st"> </span><span class="kw">factor</span>(W), <span class="dt">data =</span> dat, <span class="dt">family =</span> <span class="kw">binomial</span>())
    datn =<span class="st"> </span>dat
    predA =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
    eyA.glm.b =<span class="st"> </span><span class="kw">mean</span>(predA)
    datn[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">0</span>
    predA0 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
    eyA0.glm.b =<span class="st"> </span><span class="kw">mean</span>(predA0)
    datn[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">1</span>
    predA1 =<span class="st"> </span><span class="kw">predict</span>(glm1, <span class="dt">newdata =</span> datn, <span class="dt">type =</span> <span class="st">&quot;response&quot;</span>)
    eyA1.glm.b =<span class="st"> </span><span class="kw">mean</span>(predA1)
    crd.glm.b =<span class="st"> </span>eyA1.glm.b -<span class="st"> </span>eyA0.glm.b
    cpar.glm.b =<span class="st"> </span>eyA.glm.b -<span class="st"> </span>eyA0.glm.b
    boot.glm =<span class="st"> </span><span class="kw">rbind</span>(boot.glm, <span class="kw">c</span>(eyA0.glm.b, eyA1.glm.b, eyA.glm.b, crd.glm.b,
        cpar.glm.b))
    #### SL
    <span class="kw">attach</span>(dat)
    newdat =<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="kw">factor</span>(W -<span class="st"> </span><span class="dv">1</span>))
    <span class="kw">detach</span>(<span class="dv">2</span>)
    newdat =<span class="st"> </span><span class="kw">data.frame</span>(dat, newdat)
    newdat =<span class="st"> </span>newdat[, -<span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)]
    <span class="kw">names</span>(newdat)[<span class="dv">3</span>:<span class="dv">6</span>] =<span class="st"> </span><span class="kw">paste</span>(<span class="st">&quot;W&quot;</span>, <span class="dv">2</span>:<span class="dv">5</span>, <span class="dt">sep =</span> <span class="st">&quot;&quot;</span>)
    newX =<span class="st"> </span>newdat[, -<span class="dv">2</span>]
    YY =<span class="st"> </span>newdat[, <span class="dv">2</span>]
    SLfit =<span class="st"> </span><span class="kw">SuperLearner</span>(<span class="dt">Y =</span> YY, <span class="dt">X =</span> newX, <span class="dt">family =</span> <span class="kw">binomial</span>(), <span class="dt">SL.library =</span> SL.library)
    newX2 =<span class="st"> </span>newX
    newX2[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">0</span>
    p0 =<span class="st"> </span><span class="kw">predict</span>(SLfit, newX2)$pred
    newX2[, <span class="st">&quot;A&quot;</span>] =<span class="st"> </span><span class="dv">1</span>
    p1 =<span class="st"> </span><span class="kw">predict</span>(SLfit, newX2)$pred
    eyA0.SL.b =<span class="st"> </span><span class="kw">mean</span>(p0)
    eyA1.SL.b =<span class="st"> </span><span class="kw">mean</span>(p1)
    crd.SL.b =<span class="st"> </span>eyA1.SL.b -<span class="st"> </span>eyA0.SL.b
    ey.SL.b =<span class="st"> </span><span class="kw">mean</span>(SLfit$SL.predict[<span class="dv">1</span>:<span class="dv">10</span>])
    cpar.SL.b =<span class="st"> </span>ey.SL -<span class="st"> </span>eyA0.SL.b
    boot.SL =<span class="st"> </span><span class="kw">rbind</span>(boot.SL, <span class="kw">c</span>(eyA0.SL.b, eyA1.SL.b, ey.SL.b, crd.SL.b, cpar.SL.b))
    ############ TMLE
    YY =<span class="st"> </span>dat[, <span class="st">&quot;Y&quot;</span>]
    AA =<span class="st"> </span>newX[, <span class="dv">1</span>]
    WW =<span class="st"> </span><span class="kw">data.frame</span>(newX[, <span class="dv">2</span>:<span class="dv">5</span>], <span class="dt">W =</span> dat[, <span class="st">&quot;W&quot;</span>])
    tmle.rest =<span class="st"> </span><span class="kw">tmle</span>(YY, AA, WW, <span class="dt">Q.SL.library =</span> <span class="st">&quot;SL.inter2&quot;</span>, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>,
        <span class="dt">verbose =</span> <span class="ot">TRUE</span>, <span class="dt">gform =</span> A ~<span class="st"> </span>W)
    crd.tmle.b =<span class="st"> </span>tmle.rest$estimates$crd$psi
    cpar.tmle.b =<span class="st"> </span>ey.SL -<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">1</span>])
    eyA0.tmle.b =<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">1</span>])
    eyA1.tmle.b =<span class="st"> </span><span class="kw">mean</span>(tmle.rest$Qstar[, <span class="dv">2</span>])
    boot.tmle =<span class="st"> </span><span class="kw">rbind</span>(boot.tmle, <span class="kw">c</span>(eyA0.tmle.b, eyA1.tmle.b, ey.sat.b, crd.tmle.b,
        cpar.tmle.b))

}
## Name columns of data.frames storing bootstrap results for each estimator

nmes =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ey0&quot;</span>, <span class="st">&quot;ey1&quot;</span>, <span class="st">&quot;ey&quot;</span>, <span class="st">&quot;crd&quot;</span>, <span class="st">&quot;cpar&quot;</span>)
<span class="kw">colnames</span>(boot.sat) =<span class="st"> </span>nmes
<span class="kw">colnames</span>(boot.glm) =<span class="st"> </span>nmes
<span class="kw">colnames</span>(boot.SL) =<span class="st"> </span>nmes
<span class="kw">colnames</span>(boot.tmle) =<span class="st"> </span>nmes</code></pre></div>
<h2 id="crd">CRD</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rm</span>(<span class="dt">list =</span> <span class="kw">ls</span>())
<span class="kw">load</span>(<span class="st">&quot;NewSim2.rdata&quot;</span>)
## Get rid of any bootstrap results that &#39;failed&#39;
xsat =<span class="st"> </span><span class="kw">na.omit</span>(boot.sat[, <span class="dv">4</span>])
xparm =<span class="st"> </span><span class="kw">na.omit</span>(boot.glm[, <span class="dv">4</span>])
xSL =<span class="st"> </span><span class="kw">na.omit</span>(boot.SL[, <span class="dv">4</span>])
xtmle =<span class="st"> </span><span class="kw">na.omit</span>(boot.tmle[, <span class="dv">4</span>])
## Renaming boostrap results, setting some variables for displaying results
tp =<span class="st"> </span><span class="dv">12</span>
rr1 =<span class="st"> </span><span class="kw">range</span>(<span class="kw">c</span>(xsat, xparm, xSL, xtmle))
rr =<span class="st"> </span><span class="kw">c</span>(rr1[<span class="dv">1</span>] -<span class="st"> </span><span class="fl">0.02</span>, rr1[<span class="dv">2</span>] +<span class="st"> </span><span class="fl">0.02</span>)
brks =<span class="st"> </span><span class="kw">seq</span>(rr[<span class="dv">1</span>], rr[<span class="dv">2</span>], <span class="dt">length =</span> <span class="dv">20</span>)
rry =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, tp)
crd.glm =<span class="st"> </span>ATE.glm
crd.sat =<span class="st"> </span>ATE.sat
crd.SL =<span class="st"> </span>ATE.SL
crd.TMLE =<span class="st"> </span>ATE.TMLE
crd.true =<span class="st"> </span>ATE.true</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Get bootstrap SE for each estimator
se.sat =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xsat))
se.glm =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xparm))
se.SL =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xSL))
se.tmle =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xtmle))
## 95% CI
res.ci =<span class="st"> </span><span class="kw">c</span>(<span class="dt">est =</span> crd.glm, <span class="dt">se =</span> se.glm, <span class="dt">lower95 =</span> crd.glm -<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.glm, <span class="dt">upper95 =</span> crd.glm +
<span class="st">    </span><span class="fl">1.96</span> *<span class="st"> </span>se.glm, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(crd.glm/se.glm))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> crd.sat, <span class="dt">se =</span> se.sat, <span class="dt">lower95 =</span> crd.sat -<span class="st"> </span><span class="fl">1.96</span> *
<span class="st">    </span>se.sat, <span class="dt">upper95 =</span> crd.sat +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.sat, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(crd.sat/se.sat)))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> crd.SL, <span class="dt">se =</span> se.SL, <span class="dt">lower95 =</span> crd.SL -<span class="st"> </span><span class="fl">1.96</span> *
<span class="st">    </span>se.SL, <span class="dt">upper95 =</span> crd.SL +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.SL, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(crd.SL/se.SL)))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> crd.TMLE, <span class="dt">se =</span> se.tmle, <span class="dt">lower95 =</span> crd.TMLE -
<span class="st">    </span><span class="fl">1.96</span> *<span class="st"> </span>se.tmle, <span class="dt">upper95 =</span> crd.TMLE +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.tmle, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(crd.TMLE/se.tmle)))))
<span class="kw">rownames</span>(res.ci) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Simpler&quot;</span>, <span class="st">&quot;Sat&quot;</span>, <span class="st">&quot;SL&quot;</span>, <span class="st">&quot;TMLE&quot;</span>)</code></pre></div>
<p>We examine the results in <strong>?</strong>. This is not the results of testing the performance with repeated simulations; it is just an example of the output one might get comparing these different estimators on one sample. To test performance, we would apply these four estimation approaches to repeated samples from the same data generating mechanism (say 1000 repetitions) and examine the bias relative to the true value of the parameters across these repeated samples, as well as the variance of the estimators. This would indicate how each estimator performs with respect to bias and variance for this data-generating mechanism.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">est</th>
<th align="right">se</th>
<th align="right">lower95</th>
<th align="right">upper95</th>
<th align="right">pvalue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Simpler</td>
<td align="right">0.1887089</td>
<td align="right">0.0412578</td>
<td align="right">0.1078436</td>
<td align="right">0.2695742</td>
<td align="right">0.0000048</td>
</tr>
<tr class="even">
<td align="left">Sat</td>
<td align="right">0.1390236</td>
<td align="right">0.0411499</td>
<td align="right">0.0583699</td>
<td align="right">0.2196773</td>
<td align="right">0.0007289</td>
</tr>
<tr class="odd">
<td align="left">SL</td>
<td align="right">0.1588652</td>
<td align="right">0.0447598</td>
<td align="right">0.0711359</td>
<td align="right">0.2465945</td>
<td align="right">0.0003863</td>
</tr>
<tr class="even">
<td align="left">TMLE</td>
<td align="right">0.1388123</td>
<td align="right">0.0418396</td>
<td align="right">0.0568066</td>
<td align="right">0.2208180</td>
<td align="right">0.0009075</td>
</tr>
</tbody>
</table>
<h2 id="cpar-parameter">CPAR parameter</h2>
<p>Simply repeating above for CPAR.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">##### Compare bootstrap distribution of Sat Model and glm, cpar
xsat =<span class="st"> </span><span class="kw">na.omit</span>(boot.sat[, <span class="dv">5</span>])
xparm =<span class="st"> </span><span class="kw">na.omit</span>(boot.glm[, <span class="dv">5</span>])
xSL =<span class="st"> </span><span class="kw">na.omit</span>(boot.SL[, <span class="dv">5</span>])
xtmle =<span class="st"> </span><span class="kw">na.omit</span>(boot.tmle[, <span class="dv">5</span>])
tp =<span class="st"> </span><span class="dv">80</span>
rr1 =<span class="st"> </span><span class="kw">range</span>(<span class="kw">c</span>(xsat, xparm, xSL, xtmle))
rr =<span class="st"> </span><span class="kw">c</span>(rr1[<span class="dv">1</span>] -<span class="st"> </span><span class="fl">0.02</span>, rr1[<span class="dv">2</span>] +<span class="st"> </span><span class="fl">0.02</span>)
brks =<span class="st"> </span><span class="kw">seq</span>(rr[<span class="dv">1</span>], rr[<span class="dv">2</span>], <span class="dt">length =</span> <span class="dv">30</span>)
rry =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, tp)
cpar.sat =<span class="st"> </span>pim.sat
cpar.glm =<span class="st"> </span>pim.glm
cpar.SL =<span class="st"> </span>pim.SL
cpar.tmle =<span class="st"> </span>pim.tmle
cpar.true =<span class="st"> </span>pim.true
<span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))
x =<span class="st"> </span>xsat</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">se.sat =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xsat))
se.glm =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xparm))
se.SL =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xSL))
se.tmle =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(xtmle))
## 95% CI
res.ci =<span class="st"> </span><span class="kw">c</span>(<span class="dt">est =</span> cpar.glm, <span class="dt">se =</span> se.glm, <span class="dt">lower95 =</span> cpar.glm -<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.glm,
    <span class="dt">upper95 =</span> cpar.glm +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.glm, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(cpar.glm/se.glm))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> cpar.sat, <span class="dt">se =</span> se.sat, <span class="dt">lower95 =</span> cpar.sat -<span class="st"> </span><span class="fl">1.96</span> *
<span class="st">    </span>se.sat, <span class="dt">upper95 =</span> cpar.sat +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.sat, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(cpar.sat/se.sat)))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> cpar.SL, <span class="dt">se =</span> se.SL, <span class="dt">lower95 =</span> cpar.SL -<span class="st"> </span><span class="fl">1.96</span> *
<span class="st">    </span>se.SL, <span class="dt">upper95 =</span> cpar.SL +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.SL, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -<span class="st"> </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(cpar.SL/se.SL)))))
res.ci =<span class="st"> </span><span class="kw">rbind</span>(res.ci, <span class="kw">c</span>(<span class="dt">est =</span> cpar.tmle, <span class="dt">se =</span> se.tmle, <span class="dt">lower95 =</span> cpar.tmle -
<span class="st">    </span><span class="fl">1.96</span> *<span class="st"> </span>se.tmle, <span class="dt">upper95 =</span> cpar.tmle +<span class="st"> </span><span class="fl">1.96</span> *<span class="st"> </span>se.tmle, <span class="dt">pvalue =</span> <span class="dv">2</span> *<span class="st"> </span>(<span class="dv">1</span> -
<span class="st">    </span><span class="kw">pnorm</span>(<span class="kw">abs</span>(cpar.tmle/se.tmle)))))
<span class="kw">rownames</span>(res.ci) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Simpler&quot;</span>, <span class="st">&quot;Sat&quot;</span>, <span class="st">&quot;SL&quot;</span>, <span class="st">&quot;TMLE&quot;</span>)</code></pre></div>
<p>We examine the results in <strong>?</strong>.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">est</th>
<th align="right">se</th>
<th align="right">lower95</th>
<th align="right">upper95</th>
<th align="right">pvalue</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Simpler</td>
<td align="right">0.0254336</td>
<td align="right">0.0058576</td>
<td align="right">0.0139527</td>
<td align="right">0.0369146</td>
<td align="right">0.0000141</td>
</tr>
<tr class="even">
<td align="left">Sat</td>
<td align="right">0.0262809</td>
<td align="right">0.0118528</td>
<td align="right">0.0030495</td>
<td align="right">0.0495124</td>
<td align="right">0.0266039</td>
</tr>
<tr class="odd">
<td align="left">SL</td>
<td align="right">0.0323068</td>
<td align="right">0.0116972</td>
<td align="right">0.0093803</td>
<td align="right">0.0552334</td>
<td align="right">0.0057463</td>
</tr>
<tr class="even">
<td align="left">TMLE</td>
<td align="right">0.0326821</td>
<td align="right">0.0116833</td>
<td align="right">0.0097829</td>
<td align="right">0.0555814</td>
<td align="right">0.0051525</td>
</tr>
</tbody>
</table>
</body>
</html>
